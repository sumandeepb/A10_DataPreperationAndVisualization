{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "\n",
    "## We will scrape player stats from Cricinfo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import scrapy\n",
    "import json\n",
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "# custom class derived from class scrapy.Spider \n",
    "class CricInfoScrapeSpider(scrapy.Spider):\n",
    "    # (required) programmer defined name of the crawler\n",
    "    name='cricinfo-spider'\n",
    "    \n",
    "    # (required) starting url for the request scheduler\n",
    "    start_urls=[\n",
    "        'http://www.espncricinfo.com/ci/content/player/country.html?country=6;alpha=A'\n",
    "    ]\n",
    "    \n",
    "    # other variable definitions\n",
    "    first_class_batting_stats=namedtuple(\n",
    "    \"first_batting_stats\",\n",
    "    'matches, inns, not_outs, runs, highest, average, balls_faced, strike_rate, hundreds, fifties, boundaries, sixes, catches_taken, stumpings_made')\n",
    "\n",
    "    # (required) parser for each url\n",
    "    def parse(self, response):\n",
    "        sel = scrapy.Selector(text=response.body_as_unicode(),\n",
    "                              type=\"html\")\n",
    "        \n",
    "        # list of each page by alphabets A to Z\n",
    "        players_urlpath=sel.xpath(\n",
    "            '//div[@id=\"ciPlayerbyCharAtoZ\"]//ul//li//a/@href'\n",
    "        )\n",
    "        \n",
    "        # parse all urls\n",
    "        for url in players_urlpath.extract()[1:-1]:\n",
    "            url = \"http://www.espncricinfo.com\" + url\n",
    "            # chain request to parse player name pages\n",
    "            request = scrapy.Request(url,\n",
    "                                     self.parse_player_names)\n",
    "            yield request\n",
    "\n",
    "    # parser for player names\n",
    "    def parse_player_names(self,response):\n",
    "        sel = scrapy.Selector(text=response.body_as_unicode(),\n",
    "                              type=\"html\")\n",
    "        \n",
    "        # list of each player page by player name\n",
    "        urlPath=sel.xpath(\n",
    "            '//td[@class=\"ciPlayernames\"]//a/@href'\n",
    "        )\n",
    "\n",
    "        # select number of player pages from each alphabet page\n",
    "        numPages = 1\n",
    "        for url in urlPath.extract()[1:numPages + 1]:\n",
    "            url = \"http://www.espncricinfo.com\" + url\n",
    "            # chain request to parse player details\n",
    "            request = scrapy.Request(url,\n",
    "                                     self.parse_player_details)\n",
    "            request.meta['url']=url\n",
    "            yield request\n",
    "\n",
    "    # parser for player details and stats\n",
    "    def parse_player_details(self, response):\n",
    "        sel = scrapy.Selector(text=response.body_as_unicode(),\n",
    "                              type=\"html\")\n",
    "        \n",
    "        # parse for player names\n",
    "        name = sel.xpath(\n",
    "            '//div[@class=\"ciPlayernametxt\"]/div/h1/text()'\n",
    "        )\n",
    "\n",
    "        # parse for player date of birth\n",
    "        dob_place=sel.xpath(\n",
    "            '//p[@class=\"ciPlayerinformationtxt\"]/b[contains(text(), \"Born\")]/following-sibling::span/text()'\n",
    "        )\n",
    "\n",
    "        # parse for player team\n",
    "        teams=sel.xpath(\n",
    "            '//p[@class=\"ciPlayerinformationtxt\"]/b[contains(text(), \"Major teams\")]/following-sibling::span/text()'\n",
    "        )\n",
    "        \n",
    "        # parse for player batting stats\n",
    "        self.first_class_batting_stats.matches=sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[2]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.inns = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[3]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.not_outs = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[4]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.runs = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[5]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.highest = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[6]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.average = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[7]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.balls_faced = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[8]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.strike_rate = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[9]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.hundreds = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[10]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.fifties = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[11]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.boundaries = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[12]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.sixes = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[13]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.catches_taken = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[14]/text()'\n",
    "        )\n",
    "\n",
    "        self.first_class_batting_stats.stumpings_made = sel.xpath(\n",
    "            '//*[@id=\"ciHomeContentlhs\"]/div[4]/table[1]/tbody/tr[1]/td[15]/text()'\n",
    "        )\n",
    "        \n",
    "        # combine all player stats into single JSON object\n",
    "        json_stats={\n",
    "            \"matches\": re.sub('\\s+','',self.first_class_batting_stats.matches.extract()[0]),\n",
    "            \"inns\":re.sub('\\s+','',self.first_class_batting_stats.inns.extract()[0]),\n",
    "            \"not_outs\":re.sub('\\s+','',self.first_class_batting_stats.not_outs.extract()[0]),\n",
    "            \"runs\":re.sub('\\s+','',self.first_class_batting_stats.runs.extract()[0]),\n",
    "            \"highest\":re.sub('\\s+','',self.first_class_batting_stats.highest.extract()[0]),\n",
    "            \"average\":re.sub('\\s+','',self.first_class_batting_stats.average.extract()[0]),\n",
    "            \"balls_faced\":re.sub('\\s+','',self.first_class_batting_stats.balls_faced.extract()[0]),\n",
    "            \"strike_rate\":re.sub('\\s+','',self.first_class_batting_stats.strike_rate.extract()[0]),\n",
    "            \"hundreds\":re.sub('\\s+','',self.first_class_batting_stats.hundreds.extract()[0]),\n",
    "            \"fifties\":re.sub('\\s+','',self.first_class_batting_stats.fifties.extract()[0]),\n",
    "            \"boundaries\":re.sub('\\s+','',self.first_class_batting_stats.boundaries.extract()[0]),\n",
    "            \"sixes\":re.sub('\\s+','',self.first_class_batting_stats.sixes.extract()[0]),\n",
    "            \"catches_taken\":re.sub('\\s+','',self.first_class_batting_stats.catches_taken.extract()[0]),\n",
    "            \"stumps\":re.sub('\\s+','',self.first_class_batting_stats.stumpings_made.extract()[0])\n",
    "        }\n",
    "\n",
    "        # return full player info\n",
    "        yield {\n",
    "            \"name\": name.extract()[0].replace('\\n',''),\n",
    "            \"url\": response.meta['url'].replace('\\n',''),\n",
    "            \"born\": dob_place.extract()[0].replace('\\n',''),\n",
    "            \"teams\": teams.extract()[0].replace('\\n',''),\n",
    "            \"first_class\": json_stats\n",
    "\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the above code in cricinfo.py then run the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the existing players.csv\n",
    "!rm -f players.csv\n",
    "\n",
    "# the file cricinfo.py is alredy created and is present in the current folder\n",
    "!scrapy runspider -o players.csv cricinfo.py -t csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from generated CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_scraped = pd.read_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data from semi-structured to structured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all single quotes arround strings with double qoutes\n",
    "players_scraped['first_class'] = players_scraped['first_class'].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JSON fields to list\n",
    "df1 = pd.DataFrame(players_scraped['first_class'].values.tolist())\n",
    "\n",
    "# generate suitable column names for the sub-fields\n",
    "df1.columns = 'first_class.' + df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace json coloumn with multiple columns belonging to the sub-field\n",
    "final_df = pd.concat([players_scraped.drop(columns=\"first_class\"), df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
